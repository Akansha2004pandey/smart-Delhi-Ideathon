{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":78156,"sourceType":"datasetVersion","datasetId":44109}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:27:45.887312Z","iopub.execute_input":"2025-01-09T18:27:45.887631Z","iopub.status.idle":"2025-01-09T18:27:45.891615Z","shell.execute_reply.started":"2025-01-09T18:27:45.887603Z","shell.execute_reply":"2025-01-09T18:27:45.890832Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.models import Sequential,load_model,Model\nfrom keras.layers import Conv2D,MaxPool2D,Dense,Dropout,BatchNormalization,Flatten,Input\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:27:46.086348Z","iopub.execute_input":"2025-01-09T18:27:46.086648Z","iopub.status.idle":"2025-01-09T18:27:46.091560Z","shell.execute_reply.started":"2025-01-09T18:27:46.086626Z","shell.execute_reply":"2025-01-09T18:27:46.090582Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"image = \"/kaggle/input/utkface-new/UTKFace/100_0_0_20170112213500903.jpg.chip.jpg\"\nimage.split(\"_\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:29:10.735061Z","iopub.execute_input":"2025-01-09T18:29:10.735356Z","iopub.status.idle":"2025-01-09T18:29:10.741532Z","shell.execute_reply.started":"2025-01-09T18:29:10.735334Z","shell.execute_reply":"2025-01-09T18:29:10.740634Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/utkface-new/UTKFace/100',\n '0',\n '0',\n '20170112213500903.jpg.chip.jpg']"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"i  = 0\npath = \"/kaggle/input/utkface-new/UTKFace\"\nfor img in os.listdir(path):\n    print(img.split(\"_\"))\n    if(i > 2): \n        break\n    i += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:32:38.459953Z","iopub.execute_input":"2025-01-09T18:32:38.460286Z","iopub.status.idle":"2025-01-09T18:32:38.472679Z","shell.execute_reply.started":"2025-01-09T18:32:38.460258Z","shell.execute_reply":"2025-01-09T18:32:38.471862Z"}},"outputs":[{"name":"stdout","text":"['26', '0', '2', '20170104023102422.jpg.chip.jpg']\n['22', '1', '1', '20170112233644761.jpg.chip.jpg']\n['21', '1', '3', '20170105003215901.jpg.chip.jpg']\n['28', '0', '0', '20170117180555824.jpg.chip.jpg']\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"path = \"/kaggle/input/utkface-new/UTKFace\"\nimages = []\nage = []\ngender = []\nfor img in os.listdir(path):\n  ages = img.split(\"_\")[0]\n  genders = img.split(\"_\")[1]\n  img = cv2.imread(str(path)+\"/\"+str(img))\n  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n  images.append(np.array(img))\n  age.append(np.array(ages))\n  gender.append(np.array(genders))\n  \n# age = np.array(age,dtype=np.int64)\nimages = np.array(images)   #Forgot to scale image for my training. Please divide by 255 to scale. \ngender = np.array(gender,np.uint64)\n\n# x_train_age, x_test_age, y_train_age, y_test_age = train_test_split(images, age, random_state=42)\n\nx_train_gender, x_test_gender, y_train_gender, y_test_gender = train_test_split(images, gender, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:32:55.235422Z","iopub.execute_input":"2025-01-09T18:32:55.235729Z","iopub.status.idle":"2025-01-09T18:36:14.788649Z","shell.execute_reply.started":"2025-01-09T18:32:55.235705Z","shell.execute_reply":"2025-01-09T18:36:14.787819Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"x_train_gender.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:36:55.874315Z","iopub.execute_input":"2025-01-09T18:36:55.874634Z","iopub.status.idle":"2025-01-09T18:36:55.880347Z","shell.execute_reply.started":"2025-01-09T18:36:55.874610Z","shell.execute_reply":"2025-01-09T18:36:55.879109Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(17781, 200, 200, 3)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# history_age = age_model.fit(x_train_age, y_train_age, validation_data=(x_test_age, y_test_age), epochs=50)\n\n# age_model.save('age_model_50epochs.h5')\n\n################################################################\n#Define gender model and train\n##################################################\ngender_model = Sequential()\n\ngender_model.add(Conv2D(36, kernel_size=3, activation='relu', input_shape=(200,200,3)))\n\ngender_model.add(MaxPool2D(pool_size=3, strides=2))\ngender_model.add(Conv2D(64, kernel_size=3, activation='relu'))\ngender_model.add(MaxPool2D(pool_size=3, strides=2))\n\ngender_model.add(Conv2D(128, kernel_size=3, activation='relu'))\ngender_model.add(MaxPool2D(pool_size=3, strides=2))\n\ngender_model.add(Conv2D(256, kernel_size=3, activation='relu'))\ngender_model.add(MaxPool2D(pool_size=3, strides=2))\n\ngender_model.add(Conv2D(512, kernel_size=3, activation='relu'))\ngender_model.add(MaxPool2D(pool_size=3, strides=2))\n\ngender_model.add(Flatten())\ngender_model.add(Dropout(0.2))\ngender_model.add(Dense(512, activation='relu'))\ngender_model.add(Dense(1, activation='sigmoid', name='gender'))\n\ngender_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nhistory_gender = gender_model.fit(x_train_gender, y_train_gender,\n                        validation_data=(x_test_gender, y_test_gender), epochs=100)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T18:37:03.815951Z","iopub.execute_input":"2025-01-09T18:37:03.816265Z","iopub.status.idle":"2025-01-09T19:23:05.541831Z","shell.execute_reply.started":"2025-01-09T18:37:03.816243Z","shell.execute_reply":"2025-01-09T19:23:05.540753Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 72ms/step - accuracy: 0.6247 - loss: 3.1864 - val_accuracy: 0.7930 - val_loss: 0.4423\nEpoch 2/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 47ms/step - accuracy: 0.7973 - loss: 0.4425 - val_accuracy: 0.8198 - val_loss: 0.3980\nEpoch 3/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 48ms/step - accuracy: 0.8262 - loss: 0.3834 - val_accuracy: 0.8487 - val_loss: 0.3274\nEpoch 4/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8488 - loss: 0.3402 - val_accuracy: 0.8681 - val_loss: 0.2984\nEpoch 5/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8605 - loss: 0.3167 - val_accuracy: 0.8623 - val_loss: 0.3061\nEpoch 6/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8612 - loss: 0.3083 - val_accuracy: 0.8596 - val_loss: 0.2980\nEpoch 7/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8689 - loss: 0.2975 - val_accuracy: 0.8689 - val_loss: 0.2924\nEpoch 8/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8674 - loss: 0.2888 - val_accuracy: 0.8681 - val_loss: 0.2817\nEpoch 9/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8842 - loss: 0.2710 - val_accuracy: 0.8738 - val_loss: 0.2752\nEpoch 10/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8829 - loss: 0.2626 - val_accuracy: 0.8701 - val_loss: 0.2822\nEpoch 11/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8808 - loss: 0.2710 - val_accuracy: 0.8552 - val_loss: 0.3244\nEpoch 12/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - accuracy: 0.8792 - loss: 0.2698 - val_accuracy: 0.8757 - val_loss: 0.2963\nEpoch 13/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - accuracy: 0.8902 - loss: 0.2463 - val_accuracy: 0.8827 - val_loss: 0.2608\nEpoch 14/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.8938 - loss: 0.2438 - val_accuracy: 0.8780 - val_loss: 0.2830\nEpoch 15/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.8894 - loss: 0.2495 - val_accuracy: 0.8684 - val_loss: 0.2986\nEpoch 16/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.8982 - loss: 0.2304 - val_accuracy: 0.8832 - val_loss: 0.2724\nEpoch 17/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.8992 - loss: 0.2280 - val_accuracy: 0.8832 - val_loss: 0.2559\nEpoch 18/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9085 - loss: 0.2134 - val_accuracy: 0.8859 - val_loss: 0.2674\nEpoch 19/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9103 - loss: 0.2141 - val_accuracy: 0.8875 - val_loss: 0.2660\nEpoch 20/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9089 - loss: 0.2138 - val_accuracy: 0.8848 - val_loss: 0.2602\nEpoch 21/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9095 - loss: 0.2029 - val_accuracy: 0.8640 - val_loss: 0.3154\nEpoch 22/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9117 - loss: 0.2014 - val_accuracy: 0.8713 - val_loss: 0.2993\nEpoch 23/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9129 - loss: 0.1977 - val_accuracy: 0.8834 - val_loss: 0.2975\nEpoch 24/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9187 - loss: 0.1903 - val_accuracy: 0.8795 - val_loss: 0.2672\nEpoch 25/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9177 - loss: 0.1808 - val_accuracy: 0.8890 - val_loss: 0.2788\nEpoch 26/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9296 - loss: 0.1675 - val_accuracy: 0.8875 - val_loss: 0.2756\nEpoch 27/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 48ms/step - accuracy: 0.9247 - loss: 0.1743 - val_accuracy: 0.8844 - val_loss: 0.2729\nEpoch 28/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 48ms/step - accuracy: 0.9230 - loss: 0.1808 - val_accuracy: 0.8772 - val_loss: 0.3268\nEpoch 29/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9272 - loss: 0.1685 - val_accuracy: 0.8870 - val_loss: 0.2717\nEpoch 30/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9286 - loss: 0.1645 - val_accuracy: 0.8881 - val_loss: 0.2856\nEpoch 31/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9350 - loss: 0.1474 - val_accuracy: 0.8804 - val_loss: 0.3063\nEpoch 32/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9335 - loss: 0.1550 - val_accuracy: 0.8902 - val_loss: 0.2972\nEpoch 33/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9383 - loss: 0.1424 - val_accuracy: 0.8838 - val_loss: 0.3249\nEpoch 34/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9323 - loss: 0.1512 - val_accuracy: 0.8829 - val_loss: 0.2953\nEpoch 35/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9378 - loss: 0.1473 - val_accuracy: 0.8897 - val_loss: 0.2982\nEpoch 36/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9338 - loss: 0.1497 - val_accuracy: 0.8753 - val_loss: 0.3903\nEpoch 37/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9369 - loss: 0.1542 - val_accuracy: 0.8826 - val_loss: 0.3094\nEpoch 38/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9375 - loss: 0.1486 - val_accuracy: 0.8897 - val_loss: 0.3285\nEpoch 39/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9449 - loss: 0.1329 - val_accuracy: 0.8859 - val_loss: 0.3437\nEpoch 40/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9405 - loss: 0.1477 - val_accuracy: 0.8827 - val_loss: 0.3050\nEpoch 41/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9432 - loss: 0.1313 - val_accuracy: 0.8880 - val_loss: 0.2851\nEpoch 42/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9417 - loss: 0.1374 - val_accuracy: 0.8854 - val_loss: 0.3078\nEpoch 43/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9482 - loss: 0.1281 - val_accuracy: 0.8902 - val_loss: 0.3120\nEpoch 44/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9488 - loss: 0.1241 - val_accuracy: 0.8843 - val_loss: 0.4423\nEpoch 45/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9492 - loss: 0.1206 - val_accuracy: 0.8853 - val_loss: 0.3392\nEpoch 46/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9493 - loss: 0.1160 - val_accuracy: 0.8809 - val_loss: 0.3949\nEpoch 47/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9430 - loss: 0.1334 - val_accuracy: 0.8890 - val_loss: 0.3676\nEpoch 48/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9538 - loss: 0.1125 - val_accuracy: 0.8814 - val_loss: 0.3390\nEpoch 49/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9521 - loss: 0.1143 - val_accuracy: 0.8836 - val_loss: 0.3152\nEpoch 50/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9506 - loss: 0.1201 - val_accuracy: 0.8797 - val_loss: 0.3258\nEpoch 51/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9445 - loss: 0.1362 - val_accuracy: 0.8858 - val_loss: 0.4012\nEpoch 52/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9543 - loss: 0.1094 - val_accuracy: 0.8903 - val_loss: 0.3455\nEpoch 53/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9539 - loss: 0.1081 - val_accuracy: 0.8880 - val_loss: 0.3727\nEpoch 54/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9568 - loss: 0.1018 - val_accuracy: 0.8826 - val_loss: 0.4001\nEpoch 55/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9548 - loss: 0.1114 - val_accuracy: 0.8851 - val_loss: 0.3532\nEpoch 56/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9527 - loss: 0.1244 - val_accuracy: 0.8824 - val_loss: 0.3659\nEpoch 57/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9586 - loss: 0.0982 - val_accuracy: 0.8885 - val_loss: 0.3619\nEpoch 58/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9599 - loss: 0.0925 - val_accuracy: 0.8849 - val_loss: 0.3825\nEpoch 59/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9589 - loss: 0.0970 - val_accuracy: 0.8846 - val_loss: 0.3501\nEpoch 60/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9594 - loss: 0.1007 - val_accuracy: 0.8667 - val_loss: 0.4897\nEpoch 61/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9556 - loss: 0.1087 - val_accuracy: 0.8849 - val_loss: 0.4210\nEpoch 62/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9616 - loss: 0.0977 - val_accuracy: 0.8883 - val_loss: 0.4431\nEpoch 63/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9442 - loss: 0.1524 - val_accuracy: 0.8851 - val_loss: 0.4611\nEpoch 64/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9650 - loss: 0.0844 - val_accuracy: 0.8849 - val_loss: 0.4684\nEpoch 65/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9620 - loss: 0.0890 - val_accuracy: 0.8831 - val_loss: 0.4528\nEpoch 66/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9632 - loss: 0.0962 - val_accuracy: 0.8697 - val_loss: 0.3437\nEpoch 67/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9597 - loss: 0.1035 - val_accuracy: 0.8777 - val_loss: 0.4801\nEpoch 68/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9483 - loss: 0.1307 - val_accuracy: 0.8821 - val_loss: 0.3774\nEpoch 69/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9609 - loss: 0.0978 - val_accuracy: 0.8895 - val_loss: 0.4260\nEpoch 70/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9625 - loss: 0.1035 - val_accuracy: 0.8856 - val_loss: 0.3763\nEpoch 71/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9649 - loss: 0.0870 - val_accuracy: 0.8939 - val_loss: 0.3778\nEpoch 72/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9594 - loss: 0.1041 - val_accuracy: 0.8824 - val_loss: 0.4463\nEpoch 73/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9581 - loss: 0.1073 - val_accuracy: 0.8821 - val_loss: 0.3747\nEpoch 74/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9652 - loss: 0.0860 - val_accuracy: 0.8881 - val_loss: 0.4203\nEpoch 75/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9651 - loss: 0.0846 - val_accuracy: 0.8804 - val_loss: 0.4568\nEpoch 76/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9532 - loss: 0.1386 - val_accuracy: 0.8866 - val_loss: 0.4495\nEpoch 77/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9634 - loss: 0.0921 - val_accuracy: 0.8844 - val_loss: 0.4403\nEpoch 78/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9657 - loss: 0.0900 - val_accuracy: 0.8838 - val_loss: 0.4099\nEpoch 79/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9630 - loss: 0.0963 - val_accuracy: 0.8920 - val_loss: 0.4904\nEpoch 80/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9645 - loss: 0.0855 - val_accuracy: 0.8854 - val_loss: 0.4851\nEpoch 81/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9664 - loss: 0.0943 - val_accuracy: 0.8846 - val_loss: 0.4558\nEpoch 82/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9657 - loss: 0.0913 - val_accuracy: 0.8856 - val_loss: 0.5056\nEpoch 83/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9627 - loss: 0.1042 - val_accuracy: 0.8868 - val_loss: 0.3773\nEpoch 84/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9703 - loss: 0.0699 - val_accuracy: 0.8868 - val_loss: 0.4523\nEpoch 85/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9612 - loss: 0.0986 - val_accuracy: 0.8824 - val_loss: 0.5608\nEpoch 86/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9658 - loss: 0.0899 - val_accuracy: 0.8809 - val_loss: 0.4100\nEpoch 87/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9666 - loss: 0.0845 - val_accuracy: 0.8866 - val_loss: 0.4464\nEpoch 88/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9728 - loss: 0.0736 - val_accuracy: 0.8849 - val_loss: 0.5908\nEpoch 89/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9699 - loss: 0.0793 - val_accuracy: 0.8876 - val_loss: 0.4349\nEpoch 90/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9606 - loss: 0.1065 - val_accuracy: 0.8863 - val_loss: 0.4499\nEpoch 91/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9717 - loss: 0.0794 - val_accuracy: 0.8885 - val_loss: 0.5727\nEpoch 92/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9721 - loss: 0.0726 - val_accuracy: 0.8782 - val_loss: 0.5037\nEpoch 93/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9658 - loss: 0.0891 - val_accuracy: 0.8851 - val_loss: 0.4975\nEpoch 94/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9685 - loss: 0.0857 - val_accuracy: 0.8773 - val_loss: 0.6561\nEpoch 95/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9700 - loss: 0.0861 - val_accuracy: 0.8927 - val_loss: 0.5282\nEpoch 96/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9732 - loss: 0.0650 - val_accuracy: 0.8775 - val_loss: 0.4303\nEpoch 97/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9676 - loss: 0.0908 - val_accuracy: 0.8802 - val_loss: 0.4854\nEpoch 98/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9692 - loss: 0.0782 - val_accuracy: 0.8854 - val_loss: 0.4973\nEpoch 99/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9421 - loss: 0.2467 - val_accuracy: 0.8832 - val_loss: 0.3423\nEpoch 100/100\n\u001b[1m556/556\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - accuracy: 0.9557 - loss: 0.1203 - val_accuracy: 0.8859 - val_loss: 0.4348\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"gender_model.save('gender_model_100epochs.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T19:23:19.714437Z","iopub.execute_input":"2025-01-09T19:23:19.714749Z","iopub.status.idle":"2025-01-09T19:23:19.860451Z","shell.execute_reply.started":"2025-01-09T19:23:19.714725Z","shell.execute_reply":"2025-01-09T19:23:19.859623Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\n\n\n############################################################\n\nhistory = history_gender\n\n#plot the training and validation accuracy and loss at each epoch\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\nacc = history.history['accuracy']\n#acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n#val_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, 'y', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n####################################################################\nfrom keras.models import load_model\n#Test the model\nmy_model = load_model('gender_model_100epochs.h5', compile=False)\n\n\npredictions = my_model.predict(x_test_gender)\ny_pred = (predictions>= 0.5).astype(int)[:,0]\n\nfrom sklearn import metrics\nprint (\"Accuracy = \", metrics.accuracy_score(y_test_gender, y_pred))\n\n#Confusion Matrix - verify accuracy of each class\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\ncm=confusion_matrix(y_test_gender, y_pred)  \nsns.heatmap(cm, annot=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}